{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g29HOa3-YrIr",
        "outputId": "c1fe9994-ed9d-42dc-aa20-2de7b7fd251e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.9/67.9 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install gensim --quiet\n",
        "!pip install tensorflow-text==2.15.0 --quiet #15\n",
        "!pip install tensorflow==2.15.0 --quiet #15 13\n",
        "!pip install tf_keras==2.15.0 --quiet\n",
        "!pip install transformers==4.17 --quiet\n",
        "!pip install pydot --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HRCiG620ZAdh"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from tensorflow.keras.layers import Embedding, Input, Dense, Lambda\n",
        "from tensorflow.keras.models import Model\n",
        "import tensorflow.keras.backend as K\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_text as tf_text\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "import sklearn as sk\n",
        "import os\n",
        "import nltk\n",
        "from nltk.data import find\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import re\n",
        "\n",
        "\n",
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.models import KeyedVectors\n",
        "from gensim.test.utils import datapath"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QCWvoaWZZELw",
        "outputId": "1d12482d-b012-40af-a14d-739bfcd3ff0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_l9DMvvJcc6o"
      },
      "outputs": [],
      "source": [
        "wiki_data = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/wiki_movie_plots_deduped.csv\")\n",
        "import glob\n",
        "import pandas as pd\n",
        "\n",
        "# get data file names\n",
        "path =r'/content/drive/My Drive/Colab Notebooks/movie genres'\n",
        "all_files = glob.glob(path + \"/*.csv\")\n",
        "\n",
        "li = []\n",
        "\n",
        "for filename in all_files:\n",
        "    df = pd.read_csv(filename, index_col=None, header=0)\n",
        "    li.append(df)\n",
        "\n",
        "genre_dataset = pd.concat(li, axis=0, ignore_index=True)\n",
        "genre_dataset.drop_duplicates(subset=\"movie_name\", keep='first', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nMK8UFUMcxyY"
      },
      "outputs": [],
      "source": [
        "movie_genre_data = pd.merge(genre_dataset, wiki_data, left_on='movie_name', right_on='Title')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMzXcicFREXp",
        "outputId": "21319f4f-6a7e-4c90-a904-f0fec7335f0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 24 distinct genres in the 'genre' column.\n"
          ]
        }
      ],
      "source": [
        "# prompt: how many distinct genres are there in the genre column, which gives multple genres\n",
        "\n",
        "# Extract unique genres from the 'Genre' column\n",
        "unique_genres = set()\n",
        "for index, row in movie_genre_data.iterrows():\n",
        "    genres = str(row['genre']).split(', ')\n",
        "    for genre in genres:\n",
        "        unique_genres.add(genre.strip())\n",
        "\n",
        "# Count the number of distinct genres\n",
        "num_distinct_genres = len(unique_genres)\n",
        "print(f\"There are {num_distinct_genres} distinct genres in the 'genre' column.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCusMNhej2Vh",
        "outputId": "80b24b87-6e28-4f28-8ba1-e5f46e4ac656"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Drama         11818\n",
              "Action         7013\n",
              "Comedy         6590\n",
              "Romance        5697\n",
              "Crime          5291\n",
              "Adventure      4051\n",
              "Thriller       3200\n",
              "Horror         2104\n",
              "Mystery        1905\n",
              "Family         1591\n",
              "Fantasy        1317\n",
              "Sci-Fi         1141\n",
              "Biography       925\n",
              "Music           795\n",
              "Musical         771\n",
              "War             733\n",
              "History         704\n",
              "Animation       658\n",
              "Film-Noir       607\n",
              "Sport           420\n",
              "Western         301\n",
              "Game-Show         1\n",
              "Adult             1\n",
              "Reality-TV        1\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# prompt: remove rows that include genres with very low count (below 30)\n",
        "movie_genre_data['genre'].str.split(', ', expand=True).stack().value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I2vnrzjikp2p"
      },
      "outputs": [],
      "source": [
        "# prompt: drop rows with genre which include Game-Show , Adult, Reality-TV\n",
        "\n",
        "movie_genre_data = movie_genre_data[~movie_genre_data['genre'].str.contains('Game-Show')]\n",
        "movie_genre_data = movie_genre_data[~movie_genre_data['genre'].str.contains('Adult')]\n",
        "movie_genre_data = movie_genre_data[~movie_genre_data['genre'].str.contains('Reality-TV')]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOG0dr1zeS5Y",
        "outputId": "57084436-58f4-4be5-d4ef-db6b392f3308"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                Plot  Action  Adventure  \\\n",
            "0  In 2154, humans have depleted Earth's natural ...     1.0        1.0   \n",
            "1  Albus Dumbledore, Minerva McGonagall, and Rube...     0.0        1.0   \n",
            "2  In the mid-21st century, crop blights and dust...     0.0        1.0   \n",
            "3  In the mid-21st century, crop blights and dust...     0.0        1.0   \n",
            "4  As punishment for a past rebellion, the 12 dis...     1.0        1.0   \n",
            "\n",
            "   Animation  Biography  Comedy  Crime  Drama  Family  Fantasy  ...  Horror  \\\n",
            "0        0.0        0.0     0.0    0.0    0.0     0.0      1.0  ...     0.0   \n",
            "1        0.0        0.0     0.0    0.0    0.0     1.0      1.0  ...     0.0   \n",
            "2        0.0        0.0     0.0    0.0    1.0     0.0      0.0  ...     0.0   \n",
            "3        0.0        0.0     0.0    0.0    1.0     0.0      0.0  ...     0.0   \n",
            "4        0.0        0.0     0.0    0.0    0.0     0.0      0.0  ...     0.0   \n",
            "\n",
            "   Music  Musical  Mystery  Romance  Sci-Fi  Sport  Thriller  War  Western  \n",
            "0    0.0      0.0      0.0      0.0     0.0    0.0       0.0  0.0      0.0  \n",
            "1    0.0      0.0      0.0      0.0     0.0    0.0       0.0  0.0      0.0  \n",
            "2    0.0      0.0      0.0      0.0     1.0    0.0       0.0  0.0      0.0  \n",
            "3    0.0      0.0      0.0      0.0     1.0    0.0       0.0  0.0      0.0  \n",
            "4    0.0      0.0      0.0      0.0     1.0    0.0       0.0  0.0      0.0  \n",
            "\n",
            "[5 rows x 22 columns]\n"
          ]
        }
      ],
      "source": [
        "# prompt: create a new dataframe with columns movie_name, plot, and a 1 hot encoding of all the genres\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "# Extract genres and convert to a list of lists\n",
        "genres = movie_genre_data['genre'].str.split(', ').tolist()\n",
        "\n",
        "# Initialize MultiLabelBinarizer\n",
        "mlb = MultiLabelBinarizer()\n",
        "\n",
        "# Fit and transform genres to one-hot encoding\n",
        "genre_onehot = mlb.fit_transform(genres)\n",
        "\n",
        "# Create a new DataFrame with one-hot encoded genres\n",
        "genre_df = pd.DataFrame(genre_onehot, columns=mlb.classes_)\n",
        "\n",
        "# Concatenate movie_name, plot, and genre_onehot DataFrames\n",
        "new_df = pd.concat([movie_genre_data[['Plot']], genre_df], axis=1)\n",
        "\n",
        "# Display the new DataFrame\n",
        "print(new_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgz82b3rZJJm",
        "outputId": "4b955865-07bd-4ca0-910e-1bc2c2a39d67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Plot', 'Action', 'Adventure', 'Animation', 'Biography', 'Comedy',\n",
              "       'Crime', 'Drama', 'Family', 'Fantasy', 'Film-Noir', 'History', 'Horror',\n",
              "       'Music', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Sport', 'Thriller',\n",
              "       'War', 'Western'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0eteSw08GOt_",
        "outputId": "973cb55d-da76-411c-c80b-8b9b8169b307"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plot\n",
            "<class 'str'>      22829\n",
            "<class 'float'>        3\n",
            "Name: count, dtype: int64\n",
            "Plot\n",
            "<class 'str'>    22829\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# prompt: remove all rows where the plot is not a string\n",
        "\n",
        "# Check the data types of the 'Plot' column\n",
        "print(new_df['Plot'].apply(type).value_counts())\n",
        "\n",
        "# Filter rows where 'Plot' is not a string\n",
        "new_df = new_df[new_df['Plot'].apply(type) == str]\n",
        "\n",
        "# Check the data types of the 'Plot' column after filtering\n",
        "print(new_df['Plot'].apply(type).value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Me1oAiHhi1eA",
        "outputId": "e0165598-4484-4721-b616-86c09f26dcb6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train shape: (18263,)\n",
            "y_train shape: (18263, 21)\n",
            "X_test shape: (4566,)\n",
            "y_test shape: (4566, 21)\n"
          ]
        }
      ],
      "source": [
        "# prompt: create xtrain, ytrain, xtest, and ytest for this dataset, with the x being the plot, and y being a one hot encoding vector\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the dataset into features (X) and labels (y)\n",
        "X = new_df['Plot']\n",
        "y = new_df.drop(['Plot'], axis=1)\n",
        "\n",
        "# Split the data into training and testing sets (e.g., 80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_test shape:\", y_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fzy4dHMZP3UD",
        "outputId": "9413a0ce-def6-417e-c48e-23b8ac98fc01"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Action       1.0\n",
              "Adventure    1.0\n",
              "Animation    0.0\n",
              "Biography    0.0\n",
              "Comedy       0.0\n",
              "Crime        0.0\n",
              "Drama        0.0\n",
              "Family       0.0\n",
              "Fantasy      1.0\n",
              "Film-Noir    0.0\n",
              "History      0.0\n",
              "Horror       0.0\n",
              "Music        0.0\n",
              "Musical      0.0\n",
              "Mystery      0.0\n",
              "Romance      0.0\n",
              "Sci-Fi       0.0\n",
              "Sport        0.0\n",
              "Thriller     0.0\n",
              "War          0.0\n",
              "Western      0.0\n",
              "Name: 0, dtype: float64"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y.iloc[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3MkKrPkMBz1g"
      },
      "outputs": [],
      "source": [
        "# prompt: convert the data to tensorflow datasets\n",
        "train_data = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
        "test_data = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eBHhK0L8Hw5l"
      },
      "outputs": [],
      "source": [
        "train_examples, train_labels = next(iter(train_data.batch(20000)))\n",
        "test_examples, test_labels = next(iter(test_data.batch(5000)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BEoYzLWHH8Ol"
      },
      "outputs": [],
      "source": [
        "tokenizer = tf_text.WhitespaceTokenizer()\n",
        "train_tokens = tokenizer.tokenize(train_examples)\n",
        "test_tokens = tokenizer.tokenize(test_examples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vLTLCHn4IXkO"
      },
      "outputs": [],
      "source": [
        "MAX_SEQUENCE_LENGTH = 500\n",
        "NUM_CLASSES = 21"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dq5qPHA_I2BV",
        "outputId": "6b7375e8-df2f-4111-ffd0-5b7655c1b7fd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package word2vec_sample to /root/nltk_data...\n",
            "[nltk_data]   Unzipping models/word2vec_sample.zip.\n"
          ]
        }
      ],
      "source": [
        "nltk.download('word2vec_sample')\n",
        "word2vec_sample = str(find('models/word2vec_sample/pruned.word2vec.txt'))\n",
        "vec_model = gensim.models.KeyedVectors.load_word2vec_format(word2vec_sample, binary=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VCrFCbL7IyjW"
      },
      "outputs": [],
      "source": [
        "EMBEDDING_DIM = 300\n",
        "\n",
        "# initialize embedding matrix and word-to-id map:\n",
        "embedding_matrix = np.zeros((len(vec_model) + 1, EMBEDDING_DIM))\n",
        "vocab_dict = {}\n",
        "\n",
        "# build the embedding matrix and the word-to-id map:\n",
        "for i, word in enumerate(vec_model.index_to_key):\n",
        "    embedding_vector = vec_model[word]\n",
        "\n",
        "    if embedding_vector is not None:\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "        vocab_dict[word] = i\n",
        "\n",
        "# we can use the last index at the end of the vocab for unknown tokens\n",
        "vocab_dict['[UNK]'] = len(vocab_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0bafueEmIDWM"
      },
      "outputs": [],
      "source": [
        "def docs_to_vocab_ids(tokenized_texts_list, max_sequence_length = MAX_SEQUENCE_LENGTH):\n",
        "    \"\"\"\n",
        "    converting a list of strings to a list of lists of word ids\n",
        "    \"\"\"\n",
        "    texts_vocab_ids = []\n",
        "    for i, token_list in enumerate(tokenized_texts_list):\n",
        "\n",
        "        # Get the vocab id for each token in this doc ([UNK] if not in vocab)\n",
        "        vocab_ids = []\n",
        "        for token in list(token_list.numpy()):\n",
        "            decoded = token.decode('utf-8', errors='ignore')\n",
        "            if decoded in vocab_dict:\n",
        "                vocab_ids.append(vocab_dict[decoded])\n",
        "            else:\n",
        "                vocab_ids.append(vocab_dict['[UNK]'])\n",
        "\n",
        "        # Truncate text to max length, add padding up to max length\n",
        "        vocab_ids = vocab_ids[:max_sequence_length]\n",
        "        n_padding = (max_sequence_length - len(vocab_ids))\n",
        "        # For simplicity in this model, we'll just pad with uknown tokens\n",
        "        vocab_ids += [vocab_dict['[UNK]']] * n_padding\n",
        "\n",
        "        # Add this example to the list of converted docs\n",
        "        texts_vocab_ids.append(vocab_ids)\n",
        "\n",
        "        if i % 5000 == 0:\n",
        "            print('Examples processed: ', i)\n",
        "\n",
        "    print('Total examples: ', i)\n",
        "\n",
        "    return np.array(texts_vocab_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LqwU8fFoIfy1",
        "outputId": "c040b135-e4b2-452f-9e8a-3824084c1f34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Examples processed:  0\n",
            "Examples processed:  5000\n",
            "Examples processed:  10000\n",
            "Examples processed:  15000\n",
            "Total examples:  18262\n",
            "Examples processed:  0\n",
            "Total examples:  4565\n"
          ]
        }
      ],
      "source": [
        "train_input = docs_to_vocab_ids(train_tokens)\n",
        "test_input = docs_to_vocab_ids(test_tokens)\n",
        "\n",
        "train_labels = np.array(train_labels)\n",
        "test_labels = np.array(test_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWkaRbCkKbF7"
      },
      "source": [
        "## MultiLabel Bert multiclass classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "16c5ec4469a94d48a626f22954240461",
            "e47e57355d1d4a7d9247522e8981f8e3",
            "cb204005cfd3433da620594d3f2a1898",
            "2e093a10cc22468ca659c4d38f844db5",
            "0fedcf07ae5a4f428ec66e7e50bb8c9e",
            "b887f3538dee4fe98b8306b9dff44b51",
            "df7a481b6994417cba93179840090074",
            "6fd2bc97a2cd4e52bb7bcbc059249734",
            "87ed70a22b16479480dc93b64ee2446c",
            "4155ae0432fa4fa3986382eb8c3f19f2",
            "7cfe969383b6408a82cf0aba7b4fd1fd",
            "199206f9d29341e88c831c849cf792fa",
            "88e8c2c9337b4479b55e5b2560424b35",
            "624a1eb434d7492ba6298adbbe0ddb4b"
          ]
        },
        "id": "mDaHePmHKlAs",
        "outputId": "08cde64a-206c-4968-cf3e-6d4927f295b9"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "16c5ec4469a94d48a626f22954240461",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/208k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "199206f9d29341e88c831c849cf792fa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "88e8c2c9337b4479b55e5b2560424b35",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "624a1eb434d7492ba6298adbbe0ddb4b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/502M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertTokenizer, TFBertModel\n",
        "\n",
        "checkpoint = 'bert-base-cased'\n",
        "bert_tokenizer = BertTokenizer.from_pretrained(checkpoint)\n",
        "bert_model = TFBertModel.from_pretrained(checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "nQH42qPGKPEc"
      },
      "outputs": [],
      "source": [
        "def create_bert_multilabel_model(checkpoint = checkpoint,\n",
        "                                 num_classes = 21,\n",
        "                                 hidden_size=768,\n",
        "                                 dropout=0.3,\n",
        "                                 learning_rate=0.00005):\n",
        "    \"\"\"\n",
        "    Build a multi-label classification model with BERT. Use the Pooler Output for classification purposes.\n",
        "    \"\"\"\n",
        "    # Load the BERT model\n",
        "    bert_model = TFBertModel.from_pretrained(checkpoint)\n",
        "\n",
        "    # Make all BERT layers trainable\n",
        "    for layer in bert_model.layers:\n",
        "        layer.trainable = True\n",
        "\n",
        "    # Define input layers\n",
        "    input_ids = tf.keras.layers.Input(shape=(None,), dtype=tf.int64, name='input_ids_layer')\n",
        "    token_type_ids = tf.keras.layers.Input(shape=(None,), dtype=tf.int64, name='token_type_ids_layer')\n",
        "    attention_mask = tf.keras.layers.Input(shape=(None,), dtype=tf.int64, name='attention_mask_layer')\n",
        "\n",
        "    # Prepare BERT inputs\n",
        "    bert_inputs = {'input_ids': input_ids,\n",
        "                   'token_type_ids': token_type_ids,\n",
        "                   'attention_mask': attention_mask}\n",
        "\n",
        "    # Get BERT outputs\n",
        "    bert_out = bert_model(bert_inputs)\n",
        "    pooler_token = bert_out[1]\n",
        "\n",
        "    # Add hidden layer with dropout\n",
        "    hidden = tf.keras.layers.Dense(hidden_size, activation='relu', name='hidden_layer')(pooler_token)\n",
        "    hidden = tf.keras.layers.Dropout(dropout)(hidden)\n",
        "\n",
        "    # Add output layer for multi-label classification\n",
        "    classification = tf.keras.layers.Dense(num_classes, activation='sigmoid', name='classification_layer')(hidden)\n",
        "\n",
        "    # Define the model\n",
        "    classification_model = tf.keras.Model(inputs=[input_ids, token_type_ids, attention_mask], outputs=[classification])\n",
        "\n",
        "    # Compile the model with appropriate loss function and metrics\n",
        "    classification_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "                                 loss=Custom_Hamming_Loss(from_logits=False),\n",
        "                                 metrics=['accuracy'])\n",
        "\n",
        "    return classification_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "iZCiTN4lLJIc"
      },
      "outputs": [],
      "source": [
        "train_texts_bert = X_train.tolist()\n",
        "test_texts_bert = X_test.tolist()\n",
        "valid_texts_bert = train_texts_bert[16000:]\n",
        "valid_labels_bert = y_train[16000:]\n",
        "train_texts_bert = train_texts_bert[:16000]\n",
        "train_labels_bert = y_train[:16000]\n",
        "test_labels_bert = y_test\n",
        "npvalid_labels = np.asarray(valid_labels_bert)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "TLmsck7wLDxk"
      },
      "outputs": [],
      "source": [
        "def create_encodings_with_max_length(max_length):\n",
        "  train_encodings = bert_tokenizer(train_texts_bert, truncation=True, padding=True, max_length=max_length, return_tensors='tf')\n",
        "  valid_encodings = bert_tokenizer(valid_texts_bert, truncation=True, padding=True, max_length=max_length, return_tensors='tf')\n",
        "  test_encodings = bert_tokenizer(test_texts_bert, truncation=True, padding=True, max_length=max_length, return_tensors='tf')\n",
        "\n",
        "  return train_encodings, valid_encodings, test_encodings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "HOLHHtKFLRgb",
        "outputId": "c2cdefc6-b4f7-4acc-f1bd-c31e901a203c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "2000/2000 [==============================] - 424s 193ms/step - loss: 0.2839 - accuracy: 0.2557 - val_loss: nan - val_accuracy: 0.2872\n",
            "Epoch 2/3\n",
            "2000/2000 [==============================] - 376s 188ms/step - loss: 0.2520 - accuracy: 0.3148 - val_loss: nan - val_accuracy: 0.2943\n",
            "Epoch 3/3\n",
            "2000/2000 [==============================] - 379s 189ms/step - loss: 0.2233 - accuracy: 0.3568 - val_loss: nan - val_accuracy: 0.3067\n"
          ]
        }
      ],
      "source": [
        "train_encodings, valid_encodings, test_encodings = create_encodings_with_max_length(100)\n",
        "pooler_bert_model = create_bert_multilabel_model()\n",
        "\n",
        "pooler_bert_model_history = pooler_bert_model.fit([train_encodings.input_ids, train_encodings.token_type_ids, train_encodings.attention_mask],\n",
        "                                                  train_labels_bert,\n",
        "                                                  validation_data=([valid_encodings.input_ids, valid_encodings.token_type_ids, valid_encodings.attention_mask],\n",
        "                                                  npvalid_labels),\n",
        "                                                  batch_size=8,\n",
        "                                                  epochs=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "KEntV1UW6_Al",
        "outputId": "c5dbcd6f-cd08-45e2-f47a-0b7e35902dc9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "143/143 [==============================] - 33s 214ms/step\n"
          ]
        }
      ],
      "source": [
        "predictions = pooler_bert_model.predict([test_encodings.input_ids, test_encodings.token_type_ids, test_encodings.attention_mask])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e_1nyHf7ovi_"
      },
      "outputs": [],
      "source": [
        "def Custom_Hamming_Loss(y_true, y_pred):\n",
        "  return K.mean(y_true*(1-y_pred)+(1-y_true)*y_pred)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0fedcf07ae5a4f428ec66e7e50bb8c9e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16c5ec4469a94d48a626f22954240461": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e47e57355d1d4a7d9247522e8981f8e3",
              "IPY_MODEL_cb204005cfd3433da620594d3f2a1898",
              "IPY_MODEL_2e093a10cc22468ca659c4d38f844db5"
            ],
            "layout": "IPY_MODEL_0fedcf07ae5a4f428ec66e7e50bb8c9e"
          }
        },
        "2e093a10cc22468ca659c4d38f844db5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4155ae0432fa4fa3986382eb8c3f19f2",
            "placeholder": "​",
            "style": "IPY_MODEL_7cfe969383b6408a82cf0aba7b4fd1fd",
            "value": " 208k/208k [00:00&lt;00:00, 8.53MB/s]"
          }
        },
        "4155ae0432fa4fa3986382eb8c3f19f2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fd2bc97a2cd4e52bb7bcbc059249734": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7cfe969383b6408a82cf0aba7b4fd1fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "87ed70a22b16479480dc93b64ee2446c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b887f3538dee4fe98b8306b9dff44b51": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb204005cfd3433da620594d3f2a1898": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6fd2bc97a2cd4e52bb7bcbc059249734",
            "max": 213450,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_87ed70a22b16479480dc93b64ee2446c",
            "value": 213450
          }
        },
        "df7a481b6994417cba93179840090074": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e47e57355d1d4a7d9247522e8981f8e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b887f3538dee4fe98b8306b9dff44b51",
            "placeholder": "​",
            "style": "IPY_MODEL_df7a481b6994417cba93179840090074",
            "value": "Downloading: 100%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}